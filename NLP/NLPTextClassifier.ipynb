{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaModel.\n",
      "\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at xlm-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1107s 13s/step - loss: 1.6409 - accuracy: 0.1916\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 1092s 13s/step - loss: 1.6173 - accuracy: 0.1905\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 1085s 13s/step - loss: 1.5894 - accuracy: 0.2045\n",
      "22/22 [==============================] - 232s 10s/step - loss: 1.5851 - accuracy: 0.1844\n",
      "Test Accuracy: 0.18436577916145325\n",
      "22/22 [==============================] - 235s 11s/step\n",
      "Ensemble Model Accuracy: 0.18436578171091444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n",
    "\n",
    "# Load the 20 Newsgroups dataset\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "data_df = pd.DataFrame({'text': data.data, 'target': data.target})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XLM-R tokenizer and model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = TFXLMRobertaModel.from_pretrained('xlm-roberta-base', trainable=False)\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(list(train_df['text']), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_df['text']), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert the tokenized data into tensors\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_df['target'].values\n",
    ")).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_df['target'].values\n",
    ")).batch(32)\n",
    "\n",
    "# Fine-tune XLM-R on the text classification task\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "attention_mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "outputs = model({'input_ids': input_ids, 'attention_mask': attention_mask})[0]\n",
    "outputs = tf.keras.layers.GlobalAveragePooling1D()(outputs)\n",
    "outputs = tf.keras.layers.Dropout(0.1)(outputs)\n",
    "outputs = tf.keras.layers.Dense(4, activation='softmax')(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "# Compile the model\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, test_acc = model.evaluate(test_dataset)\n",
    "print('Test Accuracy:', test_acc)\n",
    "\n",
    "# Use the fine-tuned model for prediction\n",
    "preds = model.predict(test_dataset)\n",
    "pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(test_df['target'], pred_labels)\n",
    "print('Ensemble Model Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [01h 04m 48s]\n",
      "val_accuracy: 0.29646018147468567\n",
      "\n",
      "Best val_accuracy So Far: 0.3303834795951843\n",
      "Total elapsed time: 07h 49m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaModel.\n",
      "\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at xlm-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Load the 20 Newsgroups dataset\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "data_df = pd.DataFrame({'text': data.data, 'target': data.target})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XLM-R tokenizer and model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(list(train_df['text']), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_df['text']), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert the tokenized data into tensors\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_df['target'].values\n",
    ")).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_df['target'].values\n",
    ")).batch(32)\n",
    "\n",
    "# Define the HyperModel class\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = TFXLMRobertaModel.from_pretrained('xlm-roberta-base', trainable=False)\n",
    "        \n",
    "        input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "        attention_mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "        outputs = model({'input_ids': input_ids, 'attention_mask': attention_mask})[0]\n",
    "        outputs = tf.keras.layers.GlobalAveragePooling1D()(outputs)\n",
    "        outputs = tf.keras.layers.Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.1))(outputs)\n",
    "        outputs = tf.keras.layers.Dense(4, activation='softmax')(outputs)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-5, 1e-3, sampling='log'))\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Create an instance of the HyperModel\n",
    "hypermodel = MyHyperModel()\n",
    "\n",
    "# Define the tuner and perform hyperparameter tuning\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='text_classification'\n",
    ")\n",
    "\n",
    "tuner.search(train_dataset, validation_data=test_dataset, epochs=3)\n",
    "\n",
    "# Retrieve the best model and save it\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.save('best_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFXLMRobertaModel\n",
    "\n",
    "# Define a dictionary of custom objects\n",
    "custom_objects = {'TFXLMRobertaModel': TFXLMRobertaModel}\n",
    "\n",
    "# Load the model with the custom object scope\n",
    "loaded_model = tf.keras.models.load_model('best_model.h5', custom_objects=custom_objects)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning pipeline\n",
    "\n",
    "A fine-tuning pipeline for an XLM-R (Cross-lingual Language Model - RoBERTa) model refers to the process of adapting a pre-trained XLM-R model to a specific task or domain by further training it on a task-specific dataset. Fine-tuning allows the model to learn task-specific patterns and improve its performance on the target task.\n",
    "\n",
    "In the provided code snippet, the XLM-R model is loaded and then modified to suit a text classification task. The pre-trained model is used as a starting point, and the last layers are typically replaced or extended with task-specific layers. The model is then fine-tuned on a dataset specific to the text classification task.\n",
    "\n",
    "The fine-tuning pipeline typically involves the following steps:\n",
    "\n",
    "Loading the pre-trained XLM-R model: A pre-trained XLM-R model, which has been trained on a large corpus of text data, is loaded. This model has already learned general language representations.\n",
    "\n",
    "Modifying the model architecture: The last layers of the pre-trained XLM-R model are replaced or extended to match the requirements of the specific task. This may involve adding additional layers, changing the output dimensions, or modifying the activation functions.\n",
    "\n",
    "Providing task-specific data: A dataset specific to the text classification task is prepared. This dataset consists of labeled text examples, where each example is associated with a specific class or label.\n",
    "\n",
    "Fine-tuning the model: The modified model is trained on the task-specific dataset using techniques such as backpropagation and gradient descent. The model's parameters are updated to minimize the loss function and improve its performance on the classification task.\n",
    "\n",
    "Evaluating the fine-tuned model: The performance of the fine-tuned model is evaluated using appropriate evaluation metrics, such as accuracy or F1 score, on a separate validation or test dataset. This helps assess how well the model has adapted to the text classification task.\n",
    "\n",
    "The goal of the fine-tuning pipeline is to leverage the knowledge encoded in the pre-trained XLM-R model and transfer it to the specific text classification task, resulting in improved performance and better representation of the task-specific data. Fine-tuning allows the model to capture domain-specific patterns and nuances, leading to more accurate predictions on the target task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methods available to automate the process of selecting the best model architecture and modifications based on the performance on a validation set. Here are a few approaches:\n",
    "\n",
    "Grid Search: Grid search is a technique where you define a set of hyperparameters and their possible values. It exhaustively searches all possible combinations of hyperparameters and evaluates the model performance using cross-validation. This allows you to automatically select the best combination of hyperparameters.\n",
    "\n",
    "Random Search: Similar to grid search, random search involves defining a set of hyperparameters and their possible values. However, instead of exhaustively searching all combinations, random search randomly selects a subset of combinations to evaluate. This approach is beneficial when the search space is large, and evaluating all combinations is computationally expensive.\n",
    "\n",
    "Bayesian Optimization: Bayesian optimization is a more advanced technique that uses a probabilistic model to estimate the performance of different hyperparameter combinations. It intelligently explores the hyperparameter space by selecting the next set of hyperparameters based on the results of previous evaluations. This approach can efficiently find good hyperparameter settings with fewer evaluations compared to grid search or random search.\n",
    "\n",
    "Automated Hyperparameter Tuning Libraries: There are several libraries available that provide automated hyperparameter tuning capabilities, such as scikit-optimize, Optuna, or Hyperopt. These libraries implement various optimization algorithms and offer convenient interfaces to define search spaces, objective functions, and evaluation strategies.\n",
    "\n",
    "By utilizing these automated techniques, you can systematically explore different model architectures and modifications while continuously monitoring the performance on a validation set. This helps in finding the optimal combination of hyperparameters and modifications without the need for manual experimentation.\n",
    "\n",
    "Optuna, a popular library for hyperparameter optimization:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
